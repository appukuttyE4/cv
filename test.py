# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zNEf0h_AXvZoQTVIHlQ5WfKtQLeLwi-F
"""

import cv2
import matplotlib.pyplot as plt

#Negative image 
imgpath = 'car.jpg'
img = cv2.imread(imgpath)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#by default cv2 reads images in BGR so converting to RGB
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converting to grayscale
#gray = cv2.imread(imgpath, 0) 
colored_negative = abs(255-img)
gray_negative = abs(255-gray)
plt.imshow(gray_negative)

from PIL import Image, ImageOps

im = Image.open('car.jpg')
im_invert = ImageOps.invert(im)
im_invert.save('car_invert.jpg', quality=95)

print(img.shape)

#Thresholding

from PIL import Image, ImageOps
# creating a image1 object
im1 = Image.open("car.jpg")
# applying grayscale method
im2 = ImageOps.grayscale(im1)

def binarize(img):

  #initialize threshold
  thresh=200

  #convert image to greyscale
  #img=img.convert('L') 

  width,height=img.size

  #traverse through pixels 
  for x in range(width):
    for y in range(height):

      #if intensity less than threshold, assign white
      if img.getpixel((x,y)) < thresh:
        img.putpixel((x,y),0)

      #if intensity greater than threshold, assign black 
      else:
        img.putpixel((x,y),255)

  return img

bin_image=binarize(im2)
bin_image.save('car_bin.jpg', quality=95)

"""Rotation, Translation"""

#Translate
img = Image.open("car.jpg")
img = img.transform(img.size, Image.AFFINE, (1, 0, 1, 1, 0, 1))
img.save('car_translate.png')

#Rotate
img = Image.open("car.jpg")
img = img.rotate(90)
img.save('car_rotate.png')

#Resize
img = Image.open("car.jpg")
new_img = img.resize((300,300))
new_img.save('car_resize.png')
print(new_img.size)

"""Colorspace transform"""

#Colormap transform
# image path 
path = r'Z:/SEM 8/Computer Vision/image.jpeg'

# using imread()  
img = cv2.imread(path)

im1 = cv2.applyColorMap(img, cv2.COLORMAP_AUTUMN)
im2 = cv2.applyColorMap(img, cv2.COLORMAP_BONE)
im3 = cv2.applyColorMap(img, cv2.COLORMAP_JET)
im4 = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)

cv2.imshow('Image',im1)
cv2.imshow('Image',im2)
cv2.imshow('Image',im3)
cv2.imshow('Image',im4)



#Changing the higher and lower order bit values 
f, axarr2 = plt.subplots(2,2)
f.set_figwidth(10)
f.set_figheight(7)
img1 = img & 0b11110000
axarr2[0,0].imshow(img1)
img2 = img & 0b11000011
axarr2[0,1].imshow(img2)
img3 = img & 0b10000001
axarr2[1,0].imshow(img3)
img4 = img & 0b00111100
axarr2[1,1].imshow(img4)

axarr2[0, 0].set_title("4 Higher order bits to 1")
axarr2[0, 1].set_title("2 Higher order bits and lower order bits to 1")
axarr2[1, 0].set_title("1 Higher order bits and lower order bit to 1")
axarr2[1, 1].set_title("2 Higher order bits and lower order bits to 0")
f.tight_layout()

"""Annotations"""

#Annotations

import cv2
from google.colab.patches import cv2_imshow
	
# Read the image
img = cv2.imread('car.jpg')
#Display the input image
cv2_imshow(img)
cv2.waitKey(0)
print('\n\n')


# Line over image
line_img = img.copy()
pointA = (40,80)
pointB = (130,80)
cv2.line(line_img, pointA, pointB, (0,0,0), thickness=3)
cv2_imshow(line_img)
cv2.waitKey(0)
print('\n\n')


# Circle over image

circle_img = img.copy()
circle_center = (100,40)
radius =10
cv2.circle(circle_img, circle_center, radius, (0, 0, 255), thickness=3) 
cv2_imshow(circle_img)
cv2.waitKey(0)
print('\n\n')


# Filled circle over image

filledcircle_img = img.copy()
circle_center = (100,40)
radius =10
cv2.circle(filledcircle_img, circle_center, radius, (0, 0, 255), thickness=-1)

# display the output image 
cv2_imshow(filledcircle_img)
cv2.waitKey(0)
print('\n\n')

# Rectangle over image 
rect_img = img.copy()
start_point =(30,60)
end_point =(300,38)
cv2.rectangle(rect_img, start_point, end_point, (0, 0, 255), thickness= 3) 
cv2_imshow(rect_img)
cv2.waitKey(0)
print('\n\n')

# Add text
txt_img = img.copy()
text = 'Im sad '
org = (5,35)
cv2.putText(txt_img, text, org, fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 4.0, color = (0,0,0))
cv2_imshow(txt_img)
cv2.waitKey(0)
cv2.destroyAllWindows()

#Canny edge detection 


import cv2
  
img = cv2.imread("car.jpg")  # Read image
  
# Setting parameter values
t_lower = 50  # Lower Threshold
t_upper = 150  # Upper threshold
  
# Applying the Canny Edge filter
edge = cv2.Canny(img, t_lower, t_upper)
  
cv2_imshow(img)
cv2_imshow(edge)

#Noises



import skimage
import cv2

image = cv2.imread('Z:/SEM 8/Computer Vision/PS 4/Shapes.png')
image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Gaussian Noise
gaussian_noise = skimage.util.random_noise(image, mode="gaussian")
cv2.imshow('Gaussian Noise',gaussian_noise)
cv2.imwrite('Z:/SEM 8/Computer Vision/PS 4/Gaussian_noise.jpg',255*gaussian_noise)
cv2.waitKey(0)

# Poisson Noise
poisson_noise = skimage.util.random_noise(image, mode="poisson")
cv2.imshow('Poisson Noise',poisson_noise)
cv2.imwrite('Z:/SEM 8/Computer Vision/PS 4/Poisson_noise.jpg', 255*poisson_noise)
cv2.waitKey(0)


# S&P Noise
salt_and_pepper = skimage.util.random_noise(image, mode="s&p")
cv2.imshow('Salt_and_Pepper Noise',salt_and_pepper)
cv2.imwrite('Z:/SEM 8/Computer Vision/PS 4/S&P_noise.jpg', 255*salt_and_pepper)
cv2.waitKey(0)

# Note :
   
 '''   The pixel values were too close to 0 or too far away from 255 , hence imwrite()
       cannot handle that ,it considers them to be colorless and hence the multiplication with 255 '''



Noised images la filters



# -*- coding: utf-8 -*-
"""
Created on Thu Jan 19 11:23:42 2023

@author: 19pw34
"""
import skimage
import cv2

# Gaussian

g_image = cv2.imread('Z:/SEM 8/Computer Vision/PS 4/Gaussian_noise.jpg')

blur_image = cv2.blur(g_image,(9,9))
cv2.imshow('Mean Filter - Gaussian',blur_image)
medianBlur_image = cv2.medianBlur(g_image,9)
cv2.imshow('Median Filter - Gaussian',medianBlur_image)
cv2.waitKey(0)

# Poisson
p_image = cv2.imread('Z:/SEM 8/Computer Vision/PS 4/Poisson_noise.jpg')

blur_image = cv2.blur(p_image,(9,9))
cv2.imshow('Mean Filter - Poisson',blur_image)
medianBlur_image = cv2.medianBlur(p_image,9)
cv2.imshow('Median Filter - Poisson',medianBlur_image)
cv2.waitKey(0)


# Salt & Pepper
sp_image = cv2.imread('Z:/SEM 8/Computer Vision/PS 4/S&P_noise.jpg')

blur_image = cv2.blur(sp_image,(9,9))
cv2.imshow('Mean Filter - SaltPepper',blur_image)
medianBlur_image = cv2.medianBlur(sp_image,9)
cv2.imshow('Median Filter - SaltPepper',medianBlur_image)
cv2.waitKey(0)



-- Filters 


# -*- coding: utf-8 -*-
"""
Created on Thu Jan 12 11:06:39 2023

@author: 19pw34
"""
import cv2
import numpy as np
import matplotlib.pyplot as plt
image = cv2.imread('Shapes.png')
image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Mean filter
blur_image = cv2.blur(image,(9,9))
cv2.imshow('Mean Filter',blur_image)
cv2.waitKey(0)

# Median filter
medianBlur_image = cv2.medianBlur(image,9)
cv2.imshow('Median Filter',medianBlur_image)
cv2.waitKey(0)

# Gaussian Blur
gaussianBlur_image = cv2.GaussianBlur(image,(9,9),30)
cv2.imshow('Gaussian Filter',gaussianBlur_image)
cv2.waitKey(0)




-- Sobel and Prewitt

# Sobel Edge Detection
sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5)
sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5)
sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection
# Display Sobel Edge Detection Images
cv2.imshow('Sobel Horizontal', sobelx)
cv2.waitKey(0)
cv2.imshow('Sobel Vertical', sobely)
cv2.waitKey(0)
cv2.imshow('Sobel Operator', sobelxy)
cv2.waitKey(0)

# Prewitt Operator - Vertical Edges

po_filter_vert = np.array([[-1, 0, 1],
                   [-1, 0, 1],
                   [-1, 0, 1]])
img = cv2.filter2D(img_blur,-1, po_filter_vert)
cv2.imshow('Prewitt Operator - Vertical Edges',img)
cv2.waitKey(0)

# Prewitt Operator - Horizontal Edges

po_filter_hori = np.array([[-1, -1, -1],
                   [0, 0, 0],
                   [1, 1, 1]])
img = cv2.filter2D(img_blur,-1, po_filter_hori)
cv2.imshow('Prewitt Operator - Horizontal Edges',img)
cv2.waitKey(0)

#ROI
ROI 

import cv2
import numpy as np


# Read image
image = cv2.imread("Z:/SEM 8/Computer Vision/image.jpeg")

# Select ROI
r = cv2.selectROI("Select the area", image)

# Crop image
cropped_image = image[int(r[1]):int(r[1]+r[3]),
                    int(r[0]):int(r[0]+r[2])]

# Display cropped image
cv2.imshow("Cropped image", cropped_image)
cv2.waitKey(0)

#Colorspace transform

# Visualizing the R,G and B component

B,G,R = cv2.split(rubix_bright)
cv2.imshow("R_Bright",R)
cv2.imshow("G_Bright",G)
cv2.imshow("B_Bright",B)


B,G,R = cv2.split(rubix_dark)
cv2.imshow("R_Dark",R)
cv2.imshow("G_Dark",G)
cv2.imshow("B_Dark",B)

# Converting to LAB color space

brightLAB = cv2.cvtColor(rubix_bright, cv2.COLOR_BGR2LAB)
darkLAB = cv2.cvtColor(rubix_dark, cv2.COLOR_BGR2LAB)

cv2.imshow("Outdoor LAB",brightLAB)
cv2.imshow("Indoor LAB",darkLAB)

# Visualizing the L,A and B component

L,A,B = cv2.split(brightLAB)
cv2.imshow("L_Bright",L)
cv2.imshow("A_Bright",A)
cv2.imshow("B_Bright",B)


L,A,B = cv2.split(darkLAB)
cv2.imshow("L_Dark",L)
cv2.imshow("A_Dark",A)
cv2.imshow("B_Dark",B)

# Converting to YCbCr color space

brightYCB = cv2.cvtColor(rubix_bright, cv2.COLOR_BGR2YCrCb)
darkYCB = cv2.cvtColor(rubix_dark, cv2.COLOR_BGR2YCrCb)

cv2.imshow("Outdoor YCbCr",brightYCB)
cv2.imshow("Indoor YCbCr",darkYCB)

# Visualizing the Y,Cb and Cr component

Y,Cr,Cb = cv2.split(brightYCB)
cv2.imshow("Y_Bright",Y)
cv2.imshow("Cb_Bright",Cb)
cv2.imshow("Cr_Bright",Cr)


Y,Cr,Cb = cv2.split(darkYCB)
cv2.imshow("Y_Dark",Y)
cv2.imshow("Cb_Dark",Cb)
cv2.imshow("Cr_Dark",Cr)

# Converting to HSV color space

brightHSV = cv2.cvtColor(rubix_bright, cv2.COLOR_BGR2HSV)
darkHSV = cv2.cvtColor(rubix_dark, cv2.COLOR_BGR2HSV)

cv2.imshow("Outdoor HSV",brightHSV)
cv2.imshow("Indoor HSV",darkHSV)

# Visualizing the H,S and V component

H,S,V = cv2.split(brightHSV)
cv2.imshow("H_Bright",H)
cv2.imshow("S_Bright",S)
cv2.imshow("V_Bright",V)


H,S,V = cv2.split(darkHSV)
cv2.imshow("H_Dark",H)
cv2.imshow("S_Dark",S)
cv2.imshow("V_Dark",V)

cv2.waitKey(0)
cv2.destroyAllWindows()

